\chapter{NLP evolution}

\section{Feature extraction}
\subsection{Bag of words}
\subsubsection{TF-IDF}
\subsubsection{Hashing trick}

\section{Logistic regression}

\section{Convolutional neural networks(Not sure as I don't use them)}

\section{Recurrent neural networks(Not sure as I don't use them)}

\section{Trasformers}

\section{LLM}
\subsection{Bert}
\subsection{GPT-2 tokenizer}
\subsection{Roberta}
\subsection{Czechbert(Again don't use it but it's predecessor of Robeczech so just mention it i guess)}
\subsection{Robeczech}
\subsection{LLM's are few shot learners(gpt3)}

\section{Finetuning}
\subsection{Explain how it works}
\subsection{Catastrophic forgetting, gradual unfreezing, discriminative learning rates, etc. = ULMFiT}
\subsection{How to deal with long texts }
\cite{sunHowFineTuneBERT2020}

