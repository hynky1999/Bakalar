\chapwithtoc{Introduction}
Every day there are millions of articles published on the internet. Various authors write those
with different backgrounds and opinions. Their goal is, however, the same: to convey the information to the reader.
While the information is usually explicit there are some cases when it is implicit. Such implicit information 
is usually intentionally used to shape the reader's opinion. However, it's also possible
that the author inserts such implicit information unintentionally. It could
be the result of the author's background or state of the world at the time of writing.
The author's texts might be more pessimistic at the start of the week while more optimistic before the weekend.
It might also be possible that women write articles slightly differently than men do.
We thus ask ourselves the following question:
\begin{quote}
    \textit{Which and how much implicit information can be extracted from the news articles?}
\end{quote}

As there could be an infinite amount of such fingerprints, we decided to narrow the scope of our research to only:
\begin{enumerate}
    \item The category of the article
    \item Infered gender of article author's name
    \item Day of week when the article was published
    \item News server where the article was published
\end{enumerate}
We also had to narrow the domain of our research to news articles in Czech.

\section*{Related Work}
With the rise of Natural Language Processing (NLP) and Machine Learning (ML)
there has been a lot of research on implicit information in textual content.
In particular, sentiment analysis and text classification have been researched by many.
Most notably, \cite{joulinBagTricksEfficient2016} showed that a simple bag of words approach
with a few hidden layers could achieve state-of-the-art (SOTA) results while being very fast and straightforward.
\cite{zhangTextUnderstandingScratch2016} inspired by the usage of convolutional neural networks in image classification,
proposed a similar approach for text classification with excellent results.
In recent years, state-of-the-art has been achieved by the transformer models \cite{vaswaniAttentionAllYou2017d}.
Such an approach was used in \cite{devlinBERTPretrainingDeep2019a} where the authors achieved SOTA results on
all the tasks of GLUE benchmark \cite{wangGLUEMultiTaskBenchmark2019}, which among others, includes 
sentiment analysis task. Inspired by these results \cite{sunHowFineTuneBERT2020} further investigated possibilities
of fine-tuning BERT creating eight SOTA results on text classification tasks.

\section*{Our approach}
As no dataset with needed labels exists we created one of the most extensive datasets of Czech news articles. 
With more than 1.5 million articles it is on par with \cite{sidoCzertCzechBERTlike2021}.
while containing more metadata about the articles.

To test human ability on the tasks we took a subset of the dataset and tested human performance.

As for machine learning models, we fine-tuned the \textit{RobeCzech} (\cite{strakaRobeCzechCzechRoBERTa2021}),
and the \textit{Fernet-News} (\cite{leheckaComparisonCzechTransformers2021}) models. 
We have also used GPT-3 \cite{brownLanguageModelsAre2020b} to test its capabilities.

\section*{Structure of the thesis}
We start with the introduction to text classification, then provide readers with the necessary background knowledge
to understand the models we will use. We proceed to describe dataset creation and its properties.
Next, we describe the experiments we conducted and their results. Finally, we conclude with a summary of our findings.